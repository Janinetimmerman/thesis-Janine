{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sst\n",
    "import os\n",
    "import scipy.stats as sst\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.split(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file(parent_dir + '\\\\Data\\\\New\\\\lms_zone_du_new.shp') # LMS Zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modal split travel behaviour\n",
    "ovin_tb = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\lms_zone_ovin_travel_behaviour.csv', index_col=0)\n",
    "lms_tb = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\lms_zone_lms_modal_split.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovin = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\Ovin_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density\n",
    "dens = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_density.csv'), index_col=0)\n",
    "\n",
    "# Diversity\n",
    "landuse = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_diversity_lu.csv'), index_col=0)\n",
    "hist = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_historical.csv'), index_col=0)\n",
    "\n",
    "# Design\n",
    "design = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_design.csv'), index_col=0) \n",
    "\n",
    "# Destination accessibility\n",
    "dest = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_dest_access.csv'), index_col=0) \n",
    "\n",
    "# Distance to transit\n",
    "transit = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_transit.csv'), index_col=0) \n",
    "\n",
    "# Demography\n",
    "demo = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\zone_demographics.csv'), index_col=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select small selection of zones to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [627, 934, 777, 452, 680, 745, 822, 21, 1404, 187, 313, 1363, 170, 40, 1391, 172]\n",
    "ids = [626, 933, 776, 451, 679, 744, 821, 20, 1403, 186, 312, 1362, 169, 39, 1390, 171]\n",
    "\n",
    "## Uncomment if testing all the zones\n",
    "# ids = np.arange(1406) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, do simple hierarchical clustering based on a few attributes. It doesn't have to be realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(features, method='scale'):\n",
    "    \"\"\"\n",
    "    Scale the data to 0-1 or normalize the data\n",
    "\n",
    "    Parameters:\n",
    "    features: numpy array containing all the features\n",
    "    method: the type of data-scaling, string\n",
    "\n",
    "    Returns:\n",
    "    The transformed data as a numpy array\n",
    "    \"\"\"\n",
    "    if method == 'scale':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        return 'Not a valid scaler'\n",
    "    \n",
    "    return scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dest.loc[ids, 'Dist_to_center']\n",
    "x2 = design.loc[ids, 'Road_density']\n",
    "x3 = landuse.loc[ids, 'Entropy']\n",
    "x4 = transit.loc[ids, 'Distance_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(x1, x2, x3, x4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scale_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_data = linkage(data, method='ward', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram(linkage_data, color_threshold=5);\n",
    "plt.title('Dendrogram test cluster')\n",
    "plt.xlabel('Cluster number')\n",
    "plt.xticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_list = []\n",
    "\n",
    "for k in range(2, 16):\n",
    "    hier_cluster = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "    \n",
    "    labels = hier_cluster.fit_predict(data)\n",
    "\n",
    "    sil = silhouette_score(data, labels, metric = 'euclidean') \n",
    "    sil_list.append(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(2, 16), sil_list)\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.title('Silhouette score of clusters')\n",
    "plt.xticks(np.arange(2, 16))\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette score shows that 3 clusters would be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_cluster = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
    "labels = hier_cluster.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data[:, 0]\n",
    "x2 = data[:, 1]\n",
    "x3 = data[:, 2]\n",
    "x4 = data[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3)\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(7)\n",
    "ax[0, 0].scatter(x1, x2, c=labels)\n",
    "ax[0, 0].set_xlabel('Distance to center')\n",
    "ax[0, 0].set_ylabel('Road density')\n",
    "\n",
    "ax[0, 1].scatter(x1, x3, c=labels)\n",
    "ax[0, 1].set_xlabel('Distance to center')\n",
    "ax[0, 1].set_ylabel('Entropy')\n",
    "\n",
    "\n",
    "ax[0, 2].scatter(x1, x4, c=labels)\n",
    "ax[0, 2].set_xlabel('Distance to center')\n",
    "ax[0, 2].set_ylabel('Distance to station')\n",
    "\n",
    "ax[1, 0].scatter(x2, x3, c=labels)\n",
    "ax[1, 0].set_xlabel('Road density')\n",
    "ax[1, 0].set_ylabel('Entropy')\n",
    "\n",
    "ax[1, 1].scatter(x2, x4, c=labels)\n",
    "ax[1, 1].set_xlabel('Road density')\n",
    "ax[1, 1].set_ylabel('Distance to station')\n",
    "\n",
    "\n",
    "scatter = ax[1, 2].scatter(x3, x4, c=labels)\n",
    "ax[1, 2].set_xlabel('Entropy')\n",
    "ax[1, 2].set_ylabel('Distance to station')\n",
    "\n",
    "legend1 = ax[1, 2].legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper right\", title=\"Clusters\")\n",
    "ax[1, 2].add_artist(legend1)\n",
    "\n",
    "# f.suptitle('Clustering based on 4 variables');\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df['Cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OViN data points from respective zone clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0 = df[df.Cluster == 0].index\n",
    "id1 = df[df.Cluster == 1].index\n",
    "id2 = df[df.Cluster == 2].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select OViN trips based on departure zones. Don't take into account the double people or the weightfactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0 = ovin[ovin.AankZone.isin(id0 + 1)]\n",
    "o1 = ovin[ovin.AankZone.isin(id1 + 1)]\n",
    "o2 = ovin[ovin.AankZone.isin(id2 + 1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get relevant categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0 = o0[['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto', 'KHvm']].dropna()\n",
    "o1 = o1[['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto', 'KHvm']].dropna()\n",
    "o2 = o2[['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto', 'KHvm']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0['Cluster'] = 0\n",
    "o1['Cluster'] = 1\n",
    "o2['Cluster'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0.loc[o0.KHvm > 2, 'KHvm'] = 0\n",
    "o0.loc[o0.KHvm > 0, 'KHvm'] = 1\n",
    "\n",
    "o1.loc[o1.KHvm > 2, 'KHvm'] = 0\n",
    "o1.loc[o1.KHvm > 0, 'KHvm'] = 1\n",
    "\n",
    "o2.loc[o2.KHvm > 2, 'KHvm'] = 0\n",
    "o2.loc[o2.KHvm > 0, 'KHvm'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o0.mean(), o1.mean(), o2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, use zones itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o0 = demo[['Household_Size', 'Age_average', 'Income_hh_average', 'Cars_HH']].iloc[id0]\n",
    "# o1 = demo[['Household_Size', 'Age_average', 'Income_hh_average', 'Cars_HH']].iloc[id1]\n",
    "# o2 = demo[['Household_Size', 'Age_average', 'Income_hh_average', 'Cars_HH']].iloc[id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o0['Cluster'] = 0\n",
    "# o1['Cluster'] = 1\n",
    "# o2['Cluster'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o0['Car_ovin'] = ovin_tb.iloc[id0]['Car_passenger_o'] + ovin_tb.iloc[id0]['Car_driver_o']\n",
    "# o1['Car_ovin'] = ovin_tb.iloc[id1]['Car_passenger_o'] + ovin_tb.iloc[id1]['Car_driver_o']\n",
    "# o2['Car_ovin'] = ovin_tb.iloc[id2]['Car_passenger_o'] + ovin_tb.iloc[id2]['Car_driver_o']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o0 = o0.dropna()\n",
    "# o1 = o1.dropna()\n",
    "# o2 = o2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o0.mean(), o1.mean(), o2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prospensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p01 = sst.ttest_ind(o0.KHvm, o1.KHvm)\n",
    "_, p02 = sst.ttest_ind(o0.KHvm, o2.KHvm)\n",
    "_, p12 = sst.ttest_ind(o1.KHvm, o2.KHvm)\n",
    "\n",
    "# _, p01 = sst.ttest_ind(o0.Car_ovin, o1.Car_ovin)\n",
    "# _, p02 = sst.ttest_ind(o0.Car_ovin, o2.Car_ovin)\n",
    "# _, p12 = sst.ttest_ind(o1.Car_ovin, o2.Car_ovin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p01, p02, p12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All p-values are lower than 0.05 so the differences seem to be significant for now.\n",
    "\n",
    "Next step is to calculate the prospensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = pd.concat([o0, o1])\n",
    "df02 = pd.concat([o0, o2])\n",
    "df12 = pd.concat([o1, o2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df01.reset_index()\n",
    "df02 = df02.reset_index()\n",
    "df12 = df12.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02['Cluster'] = df02['Cluster'] / 2\n",
    "df12['Cluster'] = df12['Cluster'] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X01 = df01.iloc[:, 1:-2]\n",
    "X02 = df02.iloc[:, 1:-2]\n",
    "X12 = df12.iloc[:, 1:-2]\n",
    "\n",
    "y01 = df01.iloc[:, -1]\n",
    "y02 = df02.iloc[:, -1]\n",
    "y12 = df12.iloc[:, -1]\n",
    "\n",
    "# y01 = df01.iloc[:, -2]\n",
    "# y02 = df02.iloc[:, -2]\n",
    "# y12 = df12.iloc[:, -2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr01 = LogisticRegression()\n",
    "lr02 = LogisticRegression()\n",
    "lr12 = LogisticRegression()\n",
    "\n",
    "lr01.fit(X01, y01)\n",
    "lr02.fit(X02, y02)\n",
    "lr12.fit(X12, y12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "    'column':X01.columns.to_numpy(),\n",
    "    'coeff01':lr01.coef_.ravel(),\n",
    "    'coeff02':lr02.coef_.ravel(),\n",
    "    'coeff12':lr12.coef_.ravel(),\n",
    "\n",
    "})\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make predictions (i.e. the prospensity score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob01 = lr01.predict_proba(X01)\n",
    "prob02 = lr02.predict_proba(X02)\n",
    "prob12 = lr12.predict_proba(X12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01['ps'] = prob01[:, 1]\n",
    "df02['ps'] = prob02[:, 1]\n",
    "df12['ps'] = prob12[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check if there is overlap between the groups. Otherwise you cannot match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3)\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(3)\n",
    "\n",
    "ax[0].hist(df01[df01['Cluster'] == 0]['ps'], bins=20, alpha=0.8, label='cluster 0')\n",
    "ax[0].hist(df01[df01['Cluster'] == 1]['ps'], bins=20, alpha=0.5, label='cluster 1')\n",
    "ax[0].set_title('Propensity score cluster 0 an 1')\n",
    "ax[0].set_ylabel('Number of observations')\n",
    "ax[0].set_xlabel('Propensity score')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(df02[df02['Cluster'] == 0]['ps'], bins=20, alpha=0.8, label='cluster 0')\n",
    "ax[1].hist(df02[df02['Cluster'] == 1]['ps'], bins=20, alpha=0.5, label='cluster 2')\n",
    "ax[1].set_title('Propensity score cluster 0 an 2')\n",
    "# ax[1].set_ylabel('Number of observations')\n",
    "ax[1].set_xlabel('Propensity score')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].hist(df12[df12['Cluster'] == 0]['ps'], bins=20, alpha=0.8, label='cluster 1')\n",
    "ax[2].hist(df12[df12['Cluster'] == 1]['ps'], bins=20, alpha=0.5, label='cluster 2')\n",
    "ax[2].set_title('Propensity score cluster 1 an 2')\n",
    "# ax[2].set_ylabel('Number of observations')\n",
    "ax[2].set_xlabel('Propensity score')\n",
    "ax[2].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be sufficient overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(o0), len(o1), len(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neigh = 25\n",
    "caliper = 0.01\n",
    "\n",
    "knn01 = NearestNeighbors(n_neighbors=n_neigh, radius=caliper)\n",
    "knn01.fit(df01[['ps']])\n",
    "\n",
    "knn02 = NearestNeighbors(n_neighbors=n_neigh, radius=caliper)\n",
    "knn02.fit(df02[['ps']])\n",
    "\n",
    "knn12 = NearestNeighbors(n_neighbors=n_neigh, radius=caliper)\n",
    "knn12.fit(df12[['ps']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d01, n01 = knn01.kneighbors(df01[['ps']])\n",
    "d02, n02 = knn02.kneighbors(df02[['ps']])\n",
    "d12, n12 = knn12.kneighbors(df12[['ps']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match01 = []\n",
    "match02 = []\n",
    "match12 = []\n",
    "\n",
    "df = [df01, df02, df12]\n",
    "neighbour = [n01, n02, n12]\n",
    "match = [match01, match02, match12]\n",
    "\n",
    "for i in range(3):\n",
    "    for current_i, row in df[i].iterrows():\n",
    "        if row.Cluster == 0:\n",
    "            df[i].loc[current_i, 'matched'] = np.nan\n",
    "        else:\n",
    "            for idx in neighbour[i][current_i, :]:\n",
    "                if (current_i != idx) and (df[i].iloc[idx].Cluster == 0):\n",
    "                    if idx not in match[i]:\n",
    "                        df[i].loc[current_i, 'matched'] = idx\n",
    "                        match[i].append(idx)\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(match01), len(df01[df01.Cluster == 0]), len(df01[df01.Cluster == 1]))\n",
    "print(len(match02), len(df02[df02.Cluster == 0]), len(df02[df02.Cluster == 1]))\n",
    "print(len(match12), len(df12[df12.Cluster == 0]), len(df12[df12.Cluster == 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01_m = df01.dropna(subset=['matched'])\n",
    "df02_m = df02.dropna(subset=['matched'])\n",
    "df12_m = df12.dropna(subset=['matched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_id = df01_m.matched\n",
    "control_id = control_id.astype(int)\n",
    "df01_c = df01.loc[control_id, :]\n",
    "\n",
    "df01_f = pd.concat([df01_m, df01_c])\n",
    "\n",
    "\n",
    "control_id = df02_m.matched\n",
    "control_id = control_id.astype(int)\n",
    "df02_c = df02.loc[control_id, :]\n",
    "\n",
    "df02_f = pd.concat([df02_m, df02_c])\n",
    "\n",
    "control_id = df12_m.matched\n",
    "control_id = control_id.astype(int)\n",
    "df12_c = df12.loc[control_id, :]\n",
    "\n",
    "df12_f = pd.concat([df12_m, df12_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check p-value and means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02_c.mean(), df02_m.mean()\n",
    "\n",
    "# , o1.mean(), o2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p01_n = sst.ttest_ind(df01_m.KHvm, df01_c.KHvm)\n",
    "_, p02_n = sst.ttest_ind(df02_m.KHvm, df02_c.KHvm)\n",
    "_, p12_n = sst.ttest_ind(df12_m.KHvm, df12_c.KHvm)\n",
    "\n",
    "# _, p01_n = sst.ttest_ind(df01_m.Car_ovin, df01_c.Car_ovin)\n",
    "# _, p02_n = sst.ttest_ind(df02_m.Car_ovin, df02_c.Car_ovin)\n",
    "# _, p12_n = sst.ttest_ind(df12_m.Car_ovin, df12_c.Car_ovin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p01, p02, p12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p01_n, p02_n, p12_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now only the clusters 0 and 1 and 1 and 2 are significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check from which areas this was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.iloc[id0].GEM_NAAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.iloc[id1].GEM_NAAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.iloc[id2].GEM_NAAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travel behaviour comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_tb2 = lms_tb.iloc[:, 1:8].copy()\n",
    "lms_tb2.iloc[:, 3] = lms_tb2.iloc[:, 3:5].sum(axis=1)\n",
    "lms_tb2 = lms_tb2.drop(columns='Tram/Metro_o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id0, 'Tot_population']\n",
    "r0 = ovin_tb.iloc[id0, 1:7].multiply(pop, axis='index').sum() / pop.sum()\n",
    "r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id1, 'Tot_population']\n",
    "r1 = ovin_tb.iloc[id1, 1:7].multiply(pop, axis='index').sum() / pop.sum()\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id2, 'Tot_population']\n",
    "r2 = ovin_tb.iloc[id2, 1:7].multiply(pop, axis='index').sum() / pop.sum()\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for LMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id0, 'Tot_population']\n",
    "l0 = lms_tb2.iloc[id0].multiply(pop, axis='index').sum() / pop.sum()\n",
    "l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id1, 'Tot_population']\n",
    "l1 = lms_tb2.iloc[id1].multiply(pop, axis='index').sum() / pop.sum()\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = demo.loc[id2, 'Tot_population']\n",
    "l2 = lms_tb2.iloc[id2].multiply(pop, axis='index').sum() / pop.sum()\n",
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also calculate for corrected OViN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df01_m['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts1_01 = counts / counts.sum() * 100\n",
    "counts1_01\n",
    "\n",
    "# counts1_01 = ovin_tb.iloc[df01_m['index']].iloc[:, 1:7].mean()\n",
    "# l1_01 = lms_tb2.iloc[df01_m['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df01_c['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts0_01 = counts / counts.sum() * 100\n",
    "counts0_01\n",
    "\n",
    "# counts0_01 = ovin_tb.iloc[df01_c['index']].iloc[:, 1:7].mean()\n",
    "# l0_01 = lms_tb2.iloc[df01_c['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df02_m['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts2_02 = counts / counts.sum() * 100\n",
    "counts2_02\n",
    "\n",
    "# counts2_02 = ovin_tb.iloc[df02_m['index']].iloc[:, 1:7].mean()\n",
    "# l2_02 = lms_tb2.iloc[df02_m['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df02_c['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts0_02 = counts / counts.sum() * 100\n",
    "counts0_02\n",
    "\n",
    "# counts0_02 = ovin_tb.iloc[df02_c['index']].iloc[:, 1:7].mean()\n",
    "# l0_02 = lms_tb2.iloc[df02_c['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df12_m['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts2_12 = counts / counts.sum() * 100\n",
    "counts2_12\n",
    "\n",
    "# counts2_12 = ovin_tb.iloc[df12_m['index']].iloc[:, 1:7].mean()\n",
    "# l2_12 = lms_tb2.iloc[df12_m['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ovin.iloc[df12_c['index']].KHvm.value_counts()\n",
    "counts = counts.loc[[1, 2, 3, 4, 6, 7]]\n",
    "counts1_12 = counts / counts.sum() * 100\n",
    "counts1_12\n",
    "\n",
    "# counts1_12 = ovin_tb.iloc[df12_c['index']].iloc[:, 1:7].mean()\n",
    "# l1_12 = lms_tb2.iloc[df12_c['index']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3)\n",
    "f.set_figwidth(12)\n",
    "\n",
    "x = np.arange(6)\n",
    "\n",
    "ax[0].bar(x - 0.15, counts0_01, width=0.25, label='Cluster 0', color='firebrick')\n",
    "# ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "ax[0].bar(x + 0.15, counts1_01, width=0.25, label='Cluster 1', color='royalblue')\n",
    "\n",
    "ax[0].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "                      'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "                      ha='right')\n",
    "\n",
    "f.suptitle('Modal split OViN, corrected by demography')\n",
    "ax[0].set_ylabel('Percentage of mode use')\n",
    "ax[0].legend()\n",
    "ax[0].set_yticks(np.arange(0, 50, 5))\n",
    "ax[0].grid(axis='y')\n",
    "ax[0].set_axisbelow(True)\n",
    "\n",
    "\n",
    "ax[1].bar(x - 0.15, counts0_02, width=0.25, label='Cluster 0', color='firebrick')\n",
    "# ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "ax[1].bar(x + 0.15, counts2_02, width=0.25, label='Cluster 2', color='darkgreen')\n",
    "\n",
    "ax[1].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "                      'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "                      ha='right')\n",
    "\n",
    "# ax[1].set_title('Modal split OViN, corrected by demography')\n",
    "ax[1].set_ylabel('Percentage of mode use')\n",
    "ax[1].legend()\n",
    "ax[1].set_yticks(np.arange(0, 50, 5))\n",
    "ax[1].grid(axis='y')\n",
    "ax[1].set_axisbelow(True)\n",
    "\n",
    "ax[2].bar(x - 0.15, counts2_12, width=0.25, label='Cluster 2', color='darkgreen')\n",
    "# ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "ax[2].bar(x + 0.15, counts1_12, width=0.25, label='Cluster 1', color='royalblue')\n",
    "\n",
    "ax[2].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "                      'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "                      ha='right')\n",
    "\n",
    "# ax[2].set_title('Modal split OViN, corrected by demography')\n",
    "ax[2].set_ylabel('Percentage of mode use')\n",
    "ax[2].legend()\n",
    "ax[2].set_yticks(np.arange(0, 50, 5))\n",
    "ax[2].grid(axis='y')\n",
    "ax[2].set_axisbelow(True)\n",
    "\n",
    "\n",
    "# # LMS\n",
    "# f, ax = plt.subplots(1, 3)\n",
    "# f.set_figwidth(12)\n",
    "\n",
    "# x = np.arange(6)\n",
    "\n",
    "# ax[0].bar(x - 0.15, l0_01, width=0.25, label='Cluster 0', color='firebrick')\n",
    "# # ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "# ax[0].bar(x + 0.15, l1_01, width=0.25, label='Cluster 1', color='royalblue')\n",
    "\n",
    "# ax[0].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "#                       'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "#                       ha='right')\n",
    "\n",
    "# f.suptitle('Modal split LMS, corrected by demography')\n",
    "# ax[0].set_ylabel('Percentage of mode use')\n",
    "# ax[0].legend()\n",
    "# ax[0].set_yticks(np.arange(0, 50, 5))\n",
    "# ax[0].grid(axis='y')\n",
    "# ax[0].set_axisbelow(True)\n",
    "\n",
    "\n",
    "# ax[1].bar(x - 0.15, l0_02, width=0.25, label='Cluster 0', color='firebrick')\n",
    "# # ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "# ax[1].bar(x + 0.15, l2_02, width=0.25, label='Cluster 2', color='darkgreen')\n",
    "\n",
    "# ax[1].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "#                       'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "#                       ha='right')\n",
    "\n",
    "# # ax[1].set_title('Modal split OViN, corrected by demography')\n",
    "# ax[1].set_ylabel('Percentage of mode use')\n",
    "# ax[1].legend()\n",
    "# ax[1].set_yticks(np.arange(0, 50, 5))\n",
    "# ax[1].grid(axis='y')\n",
    "# ax[1].set_axisbelow(True)\n",
    "\n",
    "# ax[2].bar(x - 0.15, l2_12, width=0.25, label='Cluster 2', color='darkgreen')\n",
    "# # ax[0].bar(x, r2, width=0.2, label='Cluster 2')\n",
    "# ax[2].bar(x + 0.15, l1_12, width=0.25, label='Cluster 1', color='royalblue')\n",
    "\n",
    "# ax[2].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "#                       'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "#                       ha='right')\n",
    "\n",
    "# # ax[2].set_title('Modal split OViN, corrected by demography')\n",
    "# ax[2].set_ylabel('Percentage of mode use')\n",
    "# ax[2].legend()\n",
    "# ax[2].set_yticks(np.arange(0, 50, 5))\n",
    "# ax[2].grid(axis='y')\n",
    "# ax[2].set_axisbelow(True)\n",
    "\n",
    "\n",
    "# Real data\n",
    "f, ax = plt.subplots(1, 2)\n",
    "f.set_figwidth(12)\n",
    "\n",
    "x = np.arange(6)\n",
    "\n",
    "ax[0].bar(x - 0.25, r0, width=0.2, label='Cluster 0', color='firebrick')\n",
    "ax[0].bar(x, r2, width=0.2, label='Cluster 2', color='darkgreen')\n",
    "ax[0].bar(x + 0.25, r1, width=0.2, label='Cluster 1', color='royalblue')\n",
    "\n",
    "ax[0].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "                      'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "                      ha='right')\n",
    "\n",
    "ax[0].set_title('Modal split OViN 3 clusters, uncorrected')\n",
    "ax[0].set_ylabel('Percentage of mode use')\n",
    "ax[0].legend()\n",
    "ax[0].set_yticks(np.arange(0, 50, 5))\n",
    "ax[0].grid(axis='y')\n",
    "ax[0].set_axisbelow(True)\n",
    "\n",
    "ax[1].bar(x - 0.25, l0, width=0.2, label='Cluster 0', color='firebrick')\n",
    "ax[1].bar(x, l2, width=0.2, label='Cluster 2', color='darkgreen')\n",
    "ax[1].bar(x + 0.25, l1, width=0.2, label='Cluster 1', color='royalblue')\n",
    "\n",
    "ax[1].set_xticks(x, labels=['Car driver', 'Car passenger', 'Train', \n",
    "                      'BTM', 'Cycling', 'Walking'], rotation=45,\n",
    "                      ha='right')\n",
    "\n",
    "ax[1].set_title('Modal split LMS 3 clusters, uncorrected')\n",
    "ax[1].set_ylabel('Percentage of mode use')\n",
    "ax[1].legend()\n",
    "ax[1].set_yticks(np.arange(0, 50, 5))\n",
    "ax[1].grid(axis='y')\n",
    "ax[1].set_axisbelow(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at effect sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(d1, d2):\n",
    "\n",
    "    n1, n2 = len(d1), len(d2) # Calculate size of samples\n",
    "\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1) # Calculate variances\n",
    "\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "\n",
    "    return (u1 - u2) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD(d1, d2):\n",
    "\n",
    "    s1, s2 = np.std(d1), np.std(d2)\n",
    "\n",
    "    return 100 * (np.mean(d1) - np.mean(d2)) / np.sqrt((s1 ** 2 + s2 ** 2) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto']\n",
    "# cols = ['Household_Size', 'Age_average', 'Income_hh_average', 'Cars_HH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes_b = []\n",
    "effect_sizes_a = []\n",
    "\n",
    "\n",
    "\n",
    "for cl in cols:\n",
    "    _, p_before = sst.ttest_ind(o0[cl], o1[cl])\n",
    "    _, p_after = sst.ttest_ind(df01_c[cl], df01_m[cl])\n",
    "\n",
    "    cohen_d_before = cohen_d(o1[cl], o0[cl])\n",
    "    cohen_d_after = cohen_d(df01_m[cl], df01_c[cl])\n",
    "\n",
    "    smd_before = SMD(o1[cl], o0[cl])\n",
    "    smd_after = SMD(df01_m[cl], df01_c[cl])\n",
    "\n",
    "    effect_sizes_b.append([cl, 'before', cohen_d_before, p_before, smd_before])\n",
    "    effect_sizes_a.append([cl, 'after', cohen_d_after, p_after, smd_after])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_b01 = pd.DataFrame(effect_sizes_b)\n",
    "df_effect_a01 = pd.DataFrame(effect_sizes_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_b01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_a01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4)\n",
    "plt.bar(x - 0.15, df_effect_b01[4], width=0.25, label='Before matching')\n",
    "plt.bar(x + 0.15, df_effect_a01[4], width=0.25, label='After matching')\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "plt.axhline(-10, color='green', linestyle='--')\n",
    "\n",
    "plt.title('Standard mean differences')\n",
    "plt.legend()\n",
    "plt.xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes_b = []\n",
    "effect_sizes_a = []\n",
    "\n",
    "# cols = ['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto']\n",
    "\n",
    "for cl in cols:\n",
    "    _, p_before = sst.ttest_ind(o0[cl], o2[cl])\n",
    "    _, p_after = sst.ttest_ind(df02_c[cl], df02_m[cl])\n",
    "\n",
    "    cohen_d_before = cohen_d(o2[cl], o0[cl])\n",
    "    cohen_d_after = cohen_d(df02_m[cl], df02_c[cl])\n",
    "\n",
    "    smd_before = SMD(o2[cl], o0[cl])\n",
    "    smd_after = SMD(df02_m[cl], df02_c[cl])\n",
    "\n",
    "    effect_sizes_b.append([cl, 'before', cohen_d_before, p_before, smd_before])\n",
    "    effect_sizes_a.append([cl, 'after', cohen_d_after, p_after, smd_after])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_b02 = pd.DataFrame(effect_sizes_b)\n",
    "df_effect_a02 = pd.DataFrame(effect_sizes_a)\n",
    "\n",
    "df_effect_b02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_a02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4)\n",
    "plt.bar(x - 0.15, df_effect_b02[4], width=0.25, label='Before')\n",
    "plt.bar(x + 0.15, df_effect_a02[4], width=0.25, label='After')\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "plt.axhline(-10, color='green', linestyle='--')\n",
    "plt.title('Cluster 0 and 2')\n",
    "plt.legend()\n",
    "plt.xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes_b = []\n",
    "effect_sizes_a = []\n",
    "\n",
    "# cols = ['HHPers', 'Leeftijd', 'HHBestInk', 'HHAuto']\n",
    "\n",
    "for cl in cols:\n",
    "    _, p_before = sst.ttest_ind(o1[cl], o2[cl])\n",
    "    _, p_after = sst.ttest_ind(df12_c[cl], df12_m[cl])\n",
    "\n",
    "    cohen_d_before = cohen_d(o2[cl], o1[cl])\n",
    "    cohen_d_after = cohen_d(df12_m[cl], df12_c[cl])\n",
    "\n",
    "    smd_before = SMD(o2[cl], o1[cl])\n",
    "    smd_after = SMD(df12_m[cl], df12_c[cl])\n",
    "\n",
    "    effect_sizes_b.append([cl, 'before', cohen_d_before, p_before, smd_before])\n",
    "    effect_sizes_a.append([cl, 'after', cohen_d_after, p_after, smd_after])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_b12 = pd.DataFrame(effect_sizes_b)\n",
    "df_effect_a12 = pd.DataFrame(effect_sizes_a)\n",
    "\n",
    "df_effect_b12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_a12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4)\n",
    "plt.bar(x - 0.15, df_effect_b12[4], width=0.25, label='Before matching')\n",
    "plt.bar(x + 0.15, df_effect_a12[4], width=0.25, label='After matching')\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "plt.axhline(-10, color='green', linestyle='--')\n",
    "plt.title('Cluster 1 and 2')\n",
    "plt.legend()\n",
    "plt.xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3)\n",
    "f.set_figwidth(14)\n",
    "f.set_figheight(4)\n",
    "\n",
    "ax[0].bar(x - 0.15, df_effect_b01[4], width=0.25, label='Before matching')\n",
    "ax[0].bar(x + 0.15, df_effect_a01[4], width=0.25, label='After matching')\n",
    "ax[0].axhline(0, color='black')\n",
    "ax[0].axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "ax[0].axhline(-10, color='green', linestyle='--')\n",
    "ax[0].set_title('Cluster 0 and 1')\n",
    "ax[0].legend()\n",
    "ax[0].set_xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');\n",
    "\n",
    "\n",
    "ax[1].bar(x - 0.15, df_effect_b02[4], width=0.25, label='Before matching')\n",
    "ax[1].bar(x + 0.15, df_effect_a02[4], width=0.25, label='After matching')\n",
    "ax[1].axhline(0, color='black')\n",
    "ax[1].axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "ax[1].axhline(-10, color='green', linestyle='--')\n",
    "ax[1].set_title('Cluster 0 and 2')\n",
    "ax[1].legend()\n",
    "ax[1].set_xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');\n",
    "\n",
    "\n",
    "ax[2].bar(x - 0.15, df_effect_b12[4], width=0.25, label='Before matching')\n",
    "ax[2].bar(x + 0.15, df_effect_a12[4], width=0.25, label='After matching')\n",
    "ax[2].axhline(0, color='black')\n",
    "ax[2].axhline(10, color='green', linestyle='--', label='SMD = |10|%')\n",
    "ax[2].axhline(-10, color='green', linestyle='--')\n",
    "ax[2].set_title('Cluster 1 and 2')\n",
    "ax[2].legend()\n",
    "ax[2].set_xticks(x, labels=['Household size', 'Age', 'Income', 'Number of cars'],\n",
    "           rotation=45, ha='right');\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_yticks(np.arange(-350, 200, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate01 = counts1_01 - counts0_01\n",
    "ate02 = counts2_02 - counts0_02\n",
    "ate12 = counts2_12 - counts1_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obe01 = r1 - r0\n",
    "obe02 = r2 - r0\n",
    "obe12 = r2 - r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio01 = np.array(ate01) / np.array(obe01)\n",
    "ratio02 = np.array(ate02) / np.array(obe02)\n",
    "ratio12 = np.array(ate12) / np.array(obe12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'mode': ['Car driver', 'Car passenger', 'Train', 'BTM', 'Bike', 'Walking'],\n",
    "    'OBE01':np.array(obe01),\n",
    "    'ATE01': np.array(ate01),\n",
    "    'Ratio 01':ratio01 * 100,\n",
    "    'OBE02':np.array(obe02),\n",
    "    'ATE02': np.array(ate02),\n",
    "    'Ratio 02':ratio02 * 100,\n",
    "    'OBE12':np.array(obe12),\n",
    "    'ATE12': np.array(ate12),\n",
    "    'Ratio 12':ratio12 * 100,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.round(df_results, 2)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check with Multivariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X01 = df01.iloc[:, np.r_[1:5, 6]]\n",
    "X01 = df01.iloc[:, np.r_[1:6]]\n",
    "# y01 = df01.iloc[:, 5]\n",
    "y01 = df01.iloc[:, 6]\n",
    "\n",
    "\n",
    "# X02 = df02.iloc[:, np.r_[1:5, 6]]\n",
    "X02 = df02.iloc[:, np.r_[1:6]]\n",
    "# y02 = df02.iloc[:, 5]\n",
    "y02 = df02.iloc[:, 6]\n",
    "\n",
    "# X12 = df12.iloc[:, np.r_[1:5, 6]]\n",
    "X12 = df12.iloc[:, np.r_[1:6]]\n",
    "# y12 = df12.iloc[:, 5]\n",
    "y12 = df12.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr01 = LinearRegression()\n",
    "regr01.fit(X01, y01)\n",
    "\n",
    "regr02 = LinearRegression()\n",
    "regr02.fit(X02, y02)\n",
    "\n",
    "regr12 = LinearRegression()\n",
    "regr12.fit(X12, y12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr01.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr02.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr12.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
