{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as sst\n",
    "import os\n",
    "import scipy.stats as sst\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy import spatial\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import rand_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.split(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file(parent_dir + '\\\\Data\\\\New\\\\lms_zone_du_new.shp') # LMS Zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density\n",
    "dens = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_density.csv'), index_col=0)\n",
    "\n",
    "# Diversity\n",
    "landuse = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_diversity_lu.csv'), index_col=0)\n",
    "hist = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_historical.csv'), index_col=0)\n",
    "\n",
    "# Design\n",
    "design = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_design.csv'), index_col=0) \n",
    "\n",
    "# Destination accessibility\n",
    "dest = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_dest_access.csv'), index_col=0) \n",
    "\n",
    "# Distance to transit\n",
    "transit = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\lms_zone_transit.csv'), index_col=0) \n",
    "\n",
    "# Demography\n",
    "demo = pd.read_csv((parent_dir + '\\\\Data\\\\New\\\\zone_demographics.csv'), index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovin = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\Ovin_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modal split travel behaviour\n",
    "ovin_tb = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\lms_zone_ovin_travel_behaviour_newF.csv', index_col=0)\n",
    "lms_tb = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\lms_zone_lms_modal_split.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_tb2 = lms_tb.iloc[:, 1:8].copy()\n",
    "lms_tb2.iloc[:, 3] = lms_tb2.iloc[:, 3:5].sum(axis=1)\n",
    "lms_tb2 = lms_tb2.drop(columns='Tram/Metro_o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_orig = pd.read_csv(parent_dir + '\\\\Data\\\\New\\\\lms_modal_split_orig_abs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_tot = lms_orig.iloc[:, 1:8].sum(axis=1) # Total trips for each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_tb3 = lms_tb2.copy()\n",
    "lms_tb3['Factor'] = lms_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to create a set of clusters where the variance between the travel behaviours for OViN is as large as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(features, method='scale'):\n",
    "    \"\"\"\n",
    "    Scale the data to 0-1 or normalize the data\n",
    "\n",
    "    Parameters:\n",
    "    features: numpy array containing all the features\n",
    "    method: the type of data-scaling, string\n",
    "\n",
    "    Returns:\n",
    "    The transformed data as a numpy array\n",
    "    \"\"\"\n",
    "    if method == 'scale':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        return 'Not a valid scaler'\n",
    "    \n",
    "    return scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(1406) # Select which zones to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list with travel behaviour OViN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovin_tb.iloc[:, 1]\n",
    "ovin_list = []\n",
    "\n",
    "for i in range(6):\n",
    "    ovin_list.append(ovin_tb.iloc[:, i + 1].copy())\n",
    "\n",
    "    ovin_list[i][ovin_list[i] != ovin_list[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ovin = scale_data(list(zip(*ovin_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list with all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var = []\n",
    "dvar_labels = []\n",
    "\n",
    "for i in range(len(dens.columns) - 1):\n",
    "    d_var.append(dens.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(dens.columns[i + 1])\n",
    "\n",
    "\n",
    "for i in range(len(landuse.columns) - 1):\n",
    "    d_var.append(landuse.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(landuse.columns[i + 1])\n",
    "\n",
    "for i in range(len(hist.columns) - 1):\n",
    "    d_var.append(hist.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(hist.columns[i + 1])\n",
    "\n",
    "for i in range(len(design.columns) - 1):\n",
    "    d_var.append(design.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(design.columns[i + 1])\n",
    "\n",
    "for i in range(len(dest.columns) - 1):\n",
    "    d_var.append(dest.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(dest.columns[i + 1])\n",
    "\n",
    "for i in range(len(transit.columns) - 1):\n",
    "    d_var.append(transit.iloc[:, i + 1])\n",
    "\n",
    "    dvar_labels.append(transit.columns[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var.append(transit[['Distance_metro', 'Distance_tram']].min(axis=1))\n",
    "dvar_labels.append('Distance_TM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var.append(landuse[['Nature', 'Agricultural']].sum(axis=1))\n",
    "dvar_labels.append('Nature_Agri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var.append(transit[['Tram_stops', 'Metro_stops']].sum(axis=1))\n",
    "dvar_labels.append('TM_stops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    l = len(d_var[i][d_var[i] != d_var[i]])\n",
    "\n",
    "    if l > 0:\n",
    "        print(f'There are {l} missing values in {i}:{dvar_labels[i]}')\n",
    "\n",
    "    if l < 50:\n",
    "        d_var[i][d_var[i] != d_var[i]] = d_var[i].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var[36][d_var[36] != d_var[36]] = 5\n",
    "d_var[37][d_var[37] != d_var[37]] = 5\n",
    "\n",
    "d_var[40][d_var[40] != d_var[40]] = 0\n",
    "d_var[41][d_var[41] != d_var[41]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_var[-3][d_var[-3] != d_var[-3]] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, use the mean value for all categories, except for the metro and tram related variables. Give those a distance of 10 km. This is double the max 'real' distance of 5 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scale_data(list(zip(*d_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(n, data):\n",
    "    \"\"\"Perform hierarchical clustering with n clusters on data.\n",
    "    Return cluster labels\"\"\"\n",
    "\n",
    "    hier_cluster = AgglomerativeClustering(n_clusters=n, metric='euclidean', linkage='ward')\n",
    "    labels_cluster = hier_cluster.fit_predict(data)\n",
    "\n",
    "    return labels_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_df(df, weight_col):\n",
    "    \"\"\"expand the dataframe to prepare for resampling\n",
    "    result is 1 row per count per sample\"\"\"\n",
    "    df = df.reindex(df.index.repeat(df[weight_col]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modal_split_ovin(n, labels_cluster, idx=np.arange(1406)):\n",
    "\n",
    "    \"\"\"\"Calculate modal split for different clusters based on OViN data\"\"\"\n",
    "\n",
    "\n",
    "    df_list = []\n",
    "    tb_list = np.zeros((n, 6))\n",
    "    std_list = np.zeros((n, 6))\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        df_list.append(ovin_tb.iloc[idx][labels_cluster[idx] == i].copy())\n",
    "        tot = df_list[i].iloc[:, -3]\n",
    "        tb_list[i] = np.array(df_list[i].iloc[:, 1:7].multiply(tot, axis='index').sum() / tot.sum())\n",
    "\n",
    "        df_list[i][df_list[i].isnull()] = 0\n",
    "\n",
    "        for m in range(6):\n",
    "            if tot.sum() != 0:\n",
    "                std_list[i, m] = np.sqrt(np.cov(df_list[i].iloc[:, 1 + m], aweights=tot))        \n",
    "    \n",
    "    tb_list[tb_list != tb_list] = 0\n",
    "    \n",
    "    return tb_list, std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modal_split_lms(n, labels_cluster, idx=np.arange(1406)):\n",
    "    \"\"\"Calculate modal split for different clusters based on LMS data\"\"\"\n",
    "\n",
    "    lms_list = []\n",
    "    lms_tblist = np.zeros((n, 6))\n",
    "    lms_stdlist = np.zeros((n, 6))\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        lms_list.append(lms_tb2.iloc[idx][labels_cluster[idx] == i].copy())\n",
    "\n",
    "        pop = lms_tot[idx][labels_cluster[idx] == i]\n",
    "\n",
    "        lms_tblist[i] = np.array(lms_list[i].multiply(pop, axis='index').sum() / pop.sum())\n",
    "\n",
    "        lms_list[i][lms_list[i].isnull()] = 0\n",
    "\n",
    "        for m in range(6):\n",
    "            if pop.sum() != 0:\n",
    "                lms_stdlist[i, m] = np.sqrt(np.cov(lms_list[i].iloc[:, m], aweights=pop))\n",
    "    \n",
    "    lms_tblist[lms_tblist != lms_tblist] = 0\n",
    "\n",
    "    return lms_tblist, lms_stdlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_variance(tb_list):\n",
    "    \"\"\"Calculate average variance for travel behaviour\"\"\"\n",
    "    var_arr = np.zeros(6)\n",
    "\n",
    "    for i in range(6):\n",
    "        var_arr[i] = tb_list[:, i].var()\n",
    "\n",
    "    return var_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(idx, size=(10, 8), method='pearson'):\n",
    "    \"\"\"Plot correlation matrix\"\"\" \n",
    "\n",
    "    corr = pd.DataFrame(data[:, idx]).corr(method=method)\n",
    "    pval = pd.DataFrame(data[:, idx]).corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*corr.shape)\n",
    "\n",
    "    corr[pval > 0.05] = np.nan\n",
    "\n",
    "    pval[pval > 0.05] = 1\n",
    "    pval = pval[pval > 0.05]\n",
    "\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(pval, origin='lower', cmap='Greys', vmax=1, vmin=-1)\n",
    "    plt.imshow(corr, origin='lower', cmap='RdBu', vmax=1, vmin=-1)\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Pearson correlation coefficient [-]')\n",
    "    plt.title('Correlation matrix based on pearson correlation coefficient')\n",
    "    plt.xticks(np.arange(len(idx)), labels=np.array(dvar_labels)[idx], rotation=90)\n",
    "    plt.yticks(np.arange(len(idx)), labels=np.array(dvar_labels)[idx]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplots(idx, size=(7, 7)):\n",
    "    \"\"\"Plot scatter plots\"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=size)\n",
    "\n",
    "    plotz = len(np.arange(idx[0], idx[1]))\n",
    "\n",
    "    for i in range(plotz - 1):\n",
    "        for j in range(plotz):\n",
    "            if (j > i):\n",
    "                ax = plt.subplot2grid((plotz-1, plotz-1), (i,j-1))\n",
    "                \n",
    "                if i == 0:\n",
    "                    ax.set_title(f'{dvar_labels[j + idx[0]]}')\n",
    "\n",
    "                if j == i + 1:\n",
    "                    ax.set_ylabel(f'{dvar_labels[i + idx[0]]}')\n",
    "                else:\n",
    "                    ax.xaxis.set_ticklabels([])\n",
    "                    ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(data[:, i + idx[0]], data[:, j + idx[0]], s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(n, labels_cluster, tb_list, lms_list, std_tb_list, std_lms_list, idx):\n",
    "\n",
    "    mean_be = np.zeros((len(data[0, idx]), n))\n",
    "\n",
    "    for v in range(len(data[0, idx])):\n",
    "        for c in range(n):\n",
    "            \n",
    "            mean_be[v, c] = data[:, idx[v]][labels_cluster == c].mean()\n",
    "\n",
    "    x_sort = np.arange(n)[np.argsort(-tb_list[:, 0])]\n",
    "    lms_tblist = lms_list[np.argsort(-tb_list[:, 0])]\n",
    "    tb_list_n = tb_list[np.argsort(-tb_list[:, 0])]\n",
    "    mean_be = mean_be.T[np.argsort(-tb_list[:, 0])].T\n",
    "    std_tb_list_n = std_tb_list[np.argsort(-tb_list[:, 0])]\n",
    "    std_lms_list_n = std_lms_list[np.argsort(-tb_list[:, 0])]\n",
    "\n",
    "    cluster_size = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        cluster_size[i] = len(labels_cluster[labels_cluster == i])\n",
    "\n",
    "    cluster_size = cluster_size[np.argsort(-tb_list[:, 0])]\n",
    "\n",
    "    return tb_list_n, lms_tblist, x_sort, mean_be, cluster_size, std_tb_list_n, std_lms_list_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax([np.nan, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_modal_split(n, tb_list_n, lms_tblist, std_list, lms_std_list, x_sort, plot_std=True,\n",
    "                     labels_cluster=None):\n",
    "\n",
    "    if plot_std is True:\n",
    "        height = (3, 15)\n",
    "    else:\n",
    "        height = (2, 10)\n",
    "        height = (3, 15)\n",
    "\n",
    "\n",
    "    f, ax = plt.subplots(height[0], 6)\n",
    "    f.set_figwidth(17)\n",
    "    f.set_figheight(height[1])\n",
    "\n",
    "    x = np.arange(n)\n",
    "    mode_labels = ['Car driver', 'Car passenger', 'Train',\n",
    "            'BTM', '(e)-Bike', 'Walking']\n",
    "\n",
    "\n",
    "    ax[0, 0].plot([], [], color=\"#D55E00\", label='OViN', linewidth=5)\n",
    "    ax[0, 0].plot([], [], color=\"#0072B2\", label='LMS', linewidth=5)\n",
    "    ax[0, 0].plot([], [], color=\"#009E73\", label='Absolute difference OViN LMS', linewidth=5)\n",
    "    ax[0, 0].plot([], [], color=\"#E69F00\", label='Relative difference OViN LMS', linewidth=5)\n",
    "\n",
    "    if plot_std is True:\n",
    "        ax[0, 0].plot([], [], color='salmon', label='OViN - std', linewidth=5)\n",
    "        ax[0, 0].plot([], [], color='lightgreen', label='LMS - std', linewidth=5)\n",
    "\n",
    "    handles, labels = ax[0, 0].get_legend_handles_labels()\n",
    "\n",
    "    diff = (lms_tblist - tb_list_n) / tb_list_n * 100\n",
    "    max_diff = (np.nanmax(diff) // 10 + 2) * 10\n",
    "    min_diff = (np.nanmin(diff) // 10  -1) * 10\n",
    "\n",
    "\n",
    "    for i in range(6):\n",
    "        ax[0, i].bar(x - 0.18, tb_list_n[:, i], width=0.3, color=\"#D55E00\")\n",
    "        ax[0, i].bar(x + 0.18, lms_tblist[:, i], width=0.3, color=\"#0072B2\")\n",
    "\n",
    "        \n",
    "        ax[0, i].set_title(mode_labels[i])\n",
    "        ax[0, i].set_yticks(np.arange(0, tb_list_n.max() + 7, 5))\n",
    "        ax[0, i].set_xticks(np.arange(n), labels=x_sort)\n",
    "        ax[0, i].set_axisbelow(True)\n",
    "        ax[0, i].grid(axis='y')\n",
    "        ax[0, i].set_xlabel('Cluster number')\n",
    "\n",
    "\n",
    "        \n",
    "        ax[1, i].bar(x, (lms_tblist[:, i] - tb_list_n[:, i]), \n",
    "                    width=0.8, color=\"#009E73\")\n",
    "        \n",
    "        ax[2, i].bar(x, (lms_tblist[:, i] - tb_list_n[:, i]) / tb_list_n[:, i] * 100, \n",
    "                    width=0.8, color=\"#E69F00\")\n",
    "        \n",
    "\n",
    "        ax[1, i].set_title(mode_labels[i])\n",
    "        ax[1, i].set_yticks(np.arange(-14, 15, 2))\n",
    "        ax[1, i].set_xticks(np.arange(n), labels=x_sort)\n",
    "        ax[1, i].set_axisbelow(True)\n",
    "        ax[1, i].grid(axis='y')\n",
    "    \n",
    "        ax[1, i].set_xlabel('Cluster number')\n",
    "\n",
    "        \n",
    "        ax[2, i].set_title(mode_labels[i])\n",
    "        ax[2, i].set_yticks(np.arange(min_diff, max_diff + 5, 10))\n",
    "        ax[2, i].set_xticks(np.arange(n), labels=x_sort)\n",
    "        ax[2, i].set_axisbelow(True)\n",
    "        ax[2, i].grid(axis='y')\n",
    "    \n",
    "        ax[2, i].set_xlabel('Cluster number')\n",
    "\n",
    "\n",
    "    ax[0, 0].set_ylabel('Share of trips made by mode [%]')\n",
    "    ax[1, 0].set_ylabel('Absolute difference OViN - LMS [%-point]')\n",
    "    ax[2, 0].set_ylabel('Relative difference OViN - LMS [%]')\n",
    "    \n",
    "    if plot_std is True:\n",
    "        supt = 'Top: Modal split LMS and OViN for different clusters \\nMiddle: Difference OViN LMS \\nBottom: Standard deviation modal split within cluster'\n",
    "    else:\n",
    "        supt = 'Top: Modal split LMS and OViN for different clusters \\nMiddle and bottom: Difference OViN LMS'\n",
    "\n",
    "    f.legend(handles, labels, loc='upper right', bbox_to_anchor=(0.9, 1.0))\n",
    "    f.suptitle(supt,\n",
    "            fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nl(n, labels_cluster, idx=np.arange(1406), colormap='Set1'):\n",
    "\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    f.set_figwidth(15)\n",
    "    f.set_figheight(10)\n",
    "\n",
    "    cmap = plt.get_cmap(colormap, lut=n)\n",
    "\n",
    "    zones.iloc[idx].plot(ax=ax, column=labels_cluster[idx], cmap=cmap, vmin=0, vmax=n - 1,\n",
    "            legend=True, legend_kwds={\"label\": \"Cluster number\", \"ticks\": np.arange(n)})\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_facecolor('lightcyan')\n",
    "    ax.set_title('Clustering');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(n, labels_cluster, x_sort):\n",
    "\n",
    "    heatmap_relative = np.zeros((6, n))\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        for j in range(n):\n",
    "\n",
    "            cluster_zones = zones[labels_cluster == x_sort[j]]\n",
    "            size = len(cluster_zones[cluster_zones.deg_urba == i])\n",
    "            # heatmap_relative[i - 1, j] = size / len(zones[zones.deg_urba == i])\n",
    "            heatmap_relative[i - 1, j] = size / len(zones[labels_cluster == x_sort[j]])\n",
    "\n",
    "\n",
    "    plt.imshow(heatmap_relative, cmap='YlOrRd', origin='lower')\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Relative share of zones from each new cluster in each DU')\n",
    "    plt.xticks(np.arange(n), labels=x_sort)\n",
    "    plt.yticks(np.arange(6), labels=np.arange(1, 7))\n",
    "    plt.xlabel('New clusters')\n",
    "    plt.ylabel('Degree of urbanisation')\n",
    "    plt.title('Overlap degree of urbanisation and new clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting all variables, there sems to be correlation within the D-variables. So first, take a look at the individual d-variabeles and see how there are correlated. And then choose if to keep all of them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(49))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(5), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[5:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(5, 13), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([5, 13], size=(11, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[13:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(13, 18), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([13, 18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[18:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(18, 22), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([18, 22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dest accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[22:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(22, 29), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([22, 29])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dist transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_labels[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(np.arange(30, 42), size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplots([30, 42], size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with travel behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(np.hstack([data, data_ovin])).corr().iloc[:49, 49:]\n",
    "\n",
    "pval = pd.DataFrame(np.hstack([data, data_ovin])).corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:49, 49:] - np.eye(*corr.shape)\n",
    "\n",
    "corr[pval > 0.05] = np.nan\n",
    "\n",
    "pval[pval > 0.05] = 1\n",
    "pval = pval[pval > 0.05]\n",
    "\n",
    "plt.figure(figsize=(19, 15))\n",
    "plt.imshow(pval, origin='lower', cmap='Greys', vmax=1, vmin=-1)\n",
    "\n",
    "\n",
    "plt.imshow(corr, origin='lower', cmap='RdBu', vmax=1, vmin=-1)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Pearson correlation coefficient [-]')\n",
    "plt.title('Correlation matrix based on pearson correlation coefficient')\n",
    "plt.xticks(np.arange(6), labels=['Car driver', 'Car pas', 'Train', 'BTM', 'Bike', 'Walk'], rotation=90)\n",
    "plt.yticks(np.arange(len(corr)), labels=np.array(dvar_labels));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optie 1: d_idx = np.array([4, 0, 1, 29, 18]) met 5 clusters. 6 kan evt. ook\n",
    "\n",
    "Optie 2: d_idx = np.array([4, 0, 1, 29, 29, 29, 29, 18, 18, 18, 18, 3, 42, 42, 42, 42]) (dus met gewichten, 6 clusters of 7 voor beter landelijk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(np.hstack([data, data_ovin])).corr().iloc[:49, 49:]\n",
    "corr.abs().mean(axis=1).sort_values(ascending=False).index\n",
    "## Sorted variables based on average absolute correlation with travel behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.abs().iloc[:, 4].sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.abs().iloc[:, 2].sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_idx = np.array([4, 0, 1, 29, 18, 48, 6]) ## Unweighted cluster set\n",
    "d_idx = np.array([0, 1, 3, 4, 29, 29, 29, 29, 18, 18, 18, 18, 48, 48, 43, 43, 6, 6, 13, 13, 28, 28, 28, 28]) # Weighted cluster set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(d_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([data, data_ovin]))\n",
    "\n",
    "corr = df.corr()\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*corr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(np.hstack([data[:, d_idx], data_ovin])).corr().iloc[:len(d_idx), len(d_idx):]\n",
    "pval = pd.DataFrame(np.hstack([data[:, d_idx], data_ovin])).corr(method=lambda x, y: pearsonr(x, y)[1]).iloc[:len(d_idx), len(d_idx):] - np.eye(*corr.shape)\n",
    "\n",
    "corr[pval > 0.05] = np.nan\n",
    "\n",
    "pval[pval > 0.05] = 1\n",
    "pval = pval[pval > 0.05]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(pval, origin='lower', cmap='Greys', vmax=1, vmin=-1)\n",
    "plt.imshow(corr, origin='lower', cmap='RdBu', vmax=1, vmin=-1)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Pearson correlation coefficient [-]')\n",
    "plt.title('Correlation matrix based on pearson correlation coefficient')\n",
    "plt.xticks(np.arange(6), labels=['Car driver', 'Car pas', 'Train', 'BTM', 'Bike', 'Walk'], rotation=90)\n",
    "plt.yticks(np.arange(len(corr)), labels=np.array(dvar_labels)[d_idx]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_data = linkage(data[:, d_idx], method='ward', metric='euclidean')\n",
    "dendrogram(linkage_data, color_threshold=5.4)\n",
    "\n",
    "# plt.axhline(2.61, color='k', linestyle='--', label='Cut off for 7 clusters')\n",
    "plt.title('Dendrogram weighted cluster set')\n",
    "plt.xticks([])\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_list = []\n",
    "cal_list = []\n",
    "dav_list = []\n",
    "var_list = []\n",
    "\n",
    "sil_tb_list = []\n",
    "cal_tb_list = []\n",
    "dav_tb_list = []\n",
    "\n",
    "for k in range(2, 16):\n",
    "    hier_cluster = AgglomerativeClustering(n_clusters=k, metric='euclidean', linkage='ward')\n",
    "    \n",
    "    labels_cluster = hier_cluster.fit_predict(data[:, d_idx])\n",
    "\n",
    "    sil = silhouette_score(data[:, d_idx], labels_cluster, metric = 'euclidean') \n",
    "    sil_list.append(sil)\n",
    "    cal = calinski_harabasz_score(data[:, d_idx], labels_cluster)\n",
    "    cal_list.append(cal)\n",
    "    dav = davies_bouldin_score(data[:, d_idx], labels_cluster)\n",
    "    dav_list.append(dav)\n",
    "\n",
    "    # Calculate indicators for clusters based on travel behaviour\n",
    "    tb_list, std_list_s = modal_split_ovin(k, labels_cluster)\n",
    "\n",
    "    var_list.append(average_variance(tb_list))\n",
    "    sil_tb_list.append(silhouette_score(data_ovin, labels_cluster, metric = 'euclidean'))\n",
    "    cal_tb_list.append(calinski_harabasz_score(data_ovin, labels_cluster))\n",
    "    dav_tb_list.append(davies_bouldin_score(data_ovin, labels_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "ax[0].plot(np.arange(2, 16), sil_list)\n",
    "ax[0].set_xticks(np.arange(2, 16))\n",
    "ax[0].set_ylabel('Silhouette score')\n",
    "ax[0].set_xlabel('Number of clusters')\n",
    "ax[0].set_title('Silhouette score')\n",
    "ax[0].grid()\n",
    "\n",
    "\n",
    "ax[1].plot(np.arange(2, 16), cal_list)\n",
    "ax[1].set_xticks(np.arange(2, 16))\n",
    "ax[1].set_ylabel('Calinski-Harabasz score')\n",
    "ax[1].set_xlabel('Number of clusters')\n",
    "ax[1].set_title('Calinski-Harabasz score')\n",
    "ax[1].grid()\n",
    "\n",
    "\n",
    "ax[2].plot(np.arange(2, 16), dav_list)\n",
    "ax[2].set_xticks(np.arange(2, 16))\n",
    "ax[2].set_ylabel('Davies-Bouldin score')\n",
    "ax[2].set_xlabel('Number of clusters')\n",
    "ax[2].set_title('Davies-Bouldin score')\n",
    "ax[2].grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7 ## Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cluster = cluster(n, data[:, d_idx])\n",
    "tb_list, std_list = modal_split_ovin(n, labels_cluster)\n",
    "lms_list, lms_std_list = modal_split_lms(n, labels_cluster)\n",
    "average_variance(tb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_list_n, lms_tblist, x_sort, mean_be, cluster_size, std_list_n, lms_std_list_n = sort_data(n, labels_cluster, tb_list, lms_list, std_list, lms_std_list, d_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list_n.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_size, np.round(cluster_size / cluster_size.sum() * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lms_tblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modal_split(n, tb_list_n, lms_tblist, std_list_n, lms_std_list_n, x_sort, plot_std=False, labels_cluster=labels_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nl(n, labels_cluster, colormap='tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(n, labels_cluster, x_sort):\n",
    "\n",
    "    heatmap_relative = np.zeros((6, n))\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        for j in range(n):\n",
    "\n",
    "            cluster_zones = zones[labels_cluster == x_sort[j]]\n",
    "            size = len(cluster_zones[cluster_zones.deg_urba == i])\n",
    "            # heatmap_relative[i - 1, j] = size / len(zones[zones.deg_urba == i])\n",
    "            heatmap_relative[i - 1, j] = size / len(zones[labels_cluster == x_sort[j]])\n",
    "\n",
    "\n",
    "    plt.imshow(heatmap_relative, cmap='YlOrRd', origin='lower', vmax=1)\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label('Relative share of zones from each \\nweighted cluster in each DU')\n",
    "    plt.xticks(np.arange(n), labels=x_sort)\n",
    "    plt.yticks(np.arange(6), labels=np.arange(1, 7))\n",
    "    plt.xlabel('Weighted clusters')\n",
    "    plt.ylabel('Degree of urbanisation')\n",
    "    plt.title('Overlap degree of urbanisation \\nand weighted cluster set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(n, labels_cluster, x_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster = []\n",
    "\n",
    "for v in range(len(data[0, d_idx])):\n",
    "    c_list  = []\n",
    "    for c in x_sort:\n",
    "        \n",
    "       c_list.append(data[:, d_idx[v]][labels_cluster == c])\n",
    "    \n",
    "    data_cluster.append(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(data[0, d_idx]), 1)\n",
    "f.set_figheight(40)\n",
    "\n",
    "for i in range(len(data[0, d_idx])):\n",
    "    ax[i].plot(np.arange(n), mean_be[i], label=dvar_labels[d_idx[i]])\n",
    "    ax[i].boxplot(data_cluster[i], positions=np.arange(n))\n",
    "    ax[i].set_xticks(np.arange(n), labels=x_sort)\n",
    "    ax[i].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
